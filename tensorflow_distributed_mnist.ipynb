{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST distributed training  \n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow and MXNet. This tutorial focuses on how to create a convolutional neural network model to train the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using **TensorFlow distributed training**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-3bec7422fb64>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "('Writing', 'data/train.tfrecords')\n",
      "('Writing', 'data/validation.tfrecords')\n",
      "('Writing', 'data/test.tfrecords')\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1, 28, 28, 1])\r\n",
      "\r\n",
      "    # Convolutional Layer #1\r\n",
      "    conv1 = tf.layers.conv2d(\r\n",
      "        inputs=input_layer,\r\n",
      "        filters=32,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "\r\n",
      "    # Pooling Layer #1\r\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Convolutional Layer #2 and Pooling Layer #2\r\n",
      "    conv2 = tf.layers.conv2d(\r\n",
      "        inputs=pool1,\r\n",
      "        filters=64,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Dense Layer\r\n",
      "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n",
      "    dropout = tf.layers.dropout(\r\n",
      "        inputs=dense, rate=0.4, training=(mode == Modes.TRAIN))\r\n",
      "\r\n",
      "    # Logits Layer\r\n",
      "    logits = tf.layers.dense(inputs=dropout, units=10)\r\n",
      "\r\n",
      "    # Define operations\r\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\r\n",
      "        predicted_indices = tf.argmax(input=logits, axis=1)\r\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\r\n",
      "\r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.int32)\r\n",
      "        loss = tf.losses.softmax_cross_entropy(\r\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=10), logits=logits)\r\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        predictions = {\r\n",
      "            'classes': predicted_indices,\r\n",
      "            'probabilities': probabilities\r\n",
      "        }\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 784])}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n",
      "    image.set_shape([784])\r\n",
      "    image = tf.cast(image, tf.float32) * (1. / 255)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=100):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "\r\n",
      "    image, label = read_and_decode(filename_queue)\r\n",
      "    images, labels = tf.train.batch(\r\n",
      "        [image, label], batch_size=batch_size,\r\n",
      "        capacity=1000 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script here is and adaptation of the [TensorFlow MNIST example](https://github.com/tensorflow/models/tree/master/official/mnist). It provides a ```model_fn(features, labels, mode)```, which is used for training, evaluation and inference. \n",
    "\n",
    "## A regular ```model_fn```\n",
    "\n",
    "A regular **```model_fn```** follows the pattern:\n",
    "1. [defines a neural network](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L96)\n",
    "- [applies the ```features``` in the neural network](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L178)\n",
    "- [if the ```mode``` is ```PREDICT```, returns the output from the neural network](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L186)\n",
    "- [calculates the loss function comparing the output with the ```labels```](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L188)\n",
    "- [creates an optimizer and minimizes the loss function to improve the neural network](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L193)\n",
    "- [returns the output, optimizer and loss function](https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L205)\n",
    "\n",
    "## Writing a ```model_fn``` for distributed training\n",
    "When distributed training happens, the same neural network will be sent to the multiple training instances. Each instance will predict a batch of the dataset, calculate loss and minimize the optimizer. One entire loop of this process is called **training step**.\n",
    "\n",
    "### Syncronizing training steps\n",
    "A [global step](https://www.tensorflow.org/api_docs/python/tf/train/global_step) is a global variable shared between the instances. It's necessary for distributed training, so the optimizer will keep track of the number of **training steps** between runs: \n",
    "\n",
    "```python\n",
    "train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\n",
    "```\n",
    "\n",
    "That is the only required change for distributed training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-tensorflow-2018-10-31-23-19-00-978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-31 23:19:02 Starting - Starting the training job...\n",
      "2018-10-31 23:19:04 Starting - Launching requested ML instances......\n",
      "2018-10-31 23:20:11 Starting - Preparing the instances for training......\n",
      "2018-10-31 23:21:23 Downloading - Downloading input data\n",
      "2018-10-31 23:21:23 Training - Training image download completed. Training in progress.\n",
      "\u001b[32m2018-10-31 23:21:22,764 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:22,765 INFO - root - starting train task\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:22,770 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:22,793 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:22,793 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:22,799 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[32mDownloading s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,360 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,361 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,361 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,361 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,361 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,361 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'worker'}}\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,363 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,363 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9eeb97cf90>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[32mdevice_filters: \"/job:worker/task:0\"\u001b[0m\n",
      "\u001b[32mallow_soft_placement: true\u001b[0m\n",
      "\u001b[32mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[32m}\u001b[0m\n",
      "\u001b[32m, '_global_id_in_cluster': 1, '_is_chief': False, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints', '_master': u'grpc://algo-2:2222'}\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,364 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,676 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,677 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,678 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3e6d1fcf90>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints', '_master': u'grpc://algo-1:2222'}\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,680 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25.834913: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25.835727: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,992 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:25,993 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:25,382 INFO - tensorflow - Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26,018 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26,395 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26,397 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.405757: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.405798: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.422082: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.422111: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.433746: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.433780: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26,706 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.711447: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:26.711486: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27,122 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27,127 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27,158 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27.229448: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27.229492: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:27,762 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/model.ckpt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-10-31 23:21:30.235533: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:30.235567: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:30,754 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:30,757 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:30,797 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,294 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,297 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:31,014 INFO - tensorflow - loss = 2.3140526, step = 0\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,435 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,532 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,539 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:31,581 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:21:32,237 INFO - tensorflow - loss = 1.8532792, step = 3\u001b[0m\n",
      "\u001b[31m2018-10-31 23:21:46,369 INFO - tensorflow - global_step/sec: 6.57665\u001b[0m\n",
      "\u001b[32m2018-10-31 23:22:00,155 INFO - tensorflow - loss = 0.05151889, step = 194 (27.918 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:01,264 INFO - tensorflow - global_step/sec: 6.78093\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:01,872 INFO - tensorflow - loss = 0.048133977, step = 205 (30.858 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:16,116 INFO - tensorflow - global_step/sec: 6.80035\u001b[0m\n",
      "\u001b[32m2018-10-31 23:22:28,332 INFO - tensorflow - loss = 0.057389896, step = 385 (28.177 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:30,714 INFO - tensorflow - global_step/sec: 6.91882\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:33,049 INFO - tensorflow - loss = 0.026622914, step = 419 (31.177 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:22:45,453 INFO - tensorflow - global_step/sec: 6.85249\u001b[0m\n",
      "\u001b[32m2018-10-31 23:22:55,133 INFO - tensorflow - loss = 0.062729776, step = 571 (26.801 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:00,180 INFO - tensorflow - global_step/sec: 6.92606\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:03,862 INFO - tensorflow - loss = 0.030243132, step = 632 (30.813 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:14,643 INFO - tensorflow - global_step/sec: 6.98349\u001b[0m\n",
      "\u001b[32m2018-10-31 23:23:22,175 INFO - tensorflow - loss = 0.03368863, step = 759 (27.042 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:29,207 INFO - tensorflow - global_step/sec: 7.00357\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:34,924 INFO - tensorflow - loss = 0.057369914, step = 847 (31.061 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:44,164 INFO - tensorflow - global_step/sec: 6.81969\u001b[0m\n",
      "\u001b[32m2018-10-31 23:23:48,904 INFO - tensorflow - loss = 0.007432032, step = 945 (26.729 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:56,855 INFO - tensorflow - Saving checkpoints for 1002 into s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[32m2018-10-31 23:23:56,761 INFO - tensorflow - Loss for final step: 0.01894982.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:59.535417: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:59.535458: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:59,822 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:59,937 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:23:59,956 INFO - tensorflow - Starting evaluation at 2018-10-31-23:23:59\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:00,027 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:00,076 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/model.ckpt-1002\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:00,395 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:00,404 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:00,983 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:01,418 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:01,864 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:02,304 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:02,763 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:03,195 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:03,626 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04,042 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04,476 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04,951 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04,979 INFO - tensorflow - Finished evaluation at 2018-10-31-23:24:04\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04,979 INFO - tensorflow - Saving dict for global step 1002: accuracy = 0.9873, global_step = 1002, loss = 0.04109721\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04.986948: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:04.986983: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.044658: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.044698: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.064493: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.064521: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,388 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1002: s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/model.ckpt-1002\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.501464: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.501498: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.517983: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.518011: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.538269: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.538302: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.554705: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.554737: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.569604: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.569637: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.588362: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05.588389: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,635 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,694 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:05,766 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/model.ckpt-1002\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06,123 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06,123 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06,123 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.134395: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.134519: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.149793: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.149821: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.167079: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:06.167106: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.222025: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.222060: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07,266 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-23-19-00-978/checkpoints/export/Servo/temp-1541028245/saved_model.pb\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.276648: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.276678: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.711577: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.711608: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.733077: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07.733153: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07,856 INFO - tensorflow - Loss for final step: 0.043083657.\u001b[0m\n",
      "\u001b[31m2018-10-31 23:24:07,974 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1541028245/saved_model.pb\u001b[0m\n",
      "\u001b[32m2018-10-31 23:24:17,004 INFO - tf_container - master algo-1 is down, stopping parameter server\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-31 23:24:25 Uploading - Uploading generated training model\n",
      "2018-10-31 23:24:25 Completed - Training job completed\n",
      "Billable seconds: 387\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.11.0',\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "mnist_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **```fit```** method will create a training job in two **ml.c4.xlarge** instances. The logs above will show the instances doing training, evaluation, and incrementing the number of **training steps**. \n",
    "\n",
    "In the end of the training, the training job will generate a saved model for TF serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-2018-10-31-23-19-00-978\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-2018-10-31-23-19-00-978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "mnist_predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                             instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "========================================\n",
      "label is 7\n",
      "prediction is 7\n",
      "========================================\n",
      "label is 2\n",
      "prediction is 2\n",
      "========================================\n",
      "label is 1\n",
      "prediction is 1\n",
      "========================================\n",
      "label is 0\n",
      "prediction is 0\n",
      "========================================\n",
      "label is 4\n",
      "prediction is 4\n",
      "========================================\n",
      "label is 1\n",
      "prediction is 1\n",
      "========================================\n",
      "label is 4\n",
      "prediction is 4\n",
      "========================================\n",
      "label is 9\n",
      "prediction is 9\n",
      "========================================\n",
      "label is 5\n",
      "prediction is 5\n",
      "========================================\n",
      "label is 9\n",
      "prediction is 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "for i in range(10):\n",
    "    data = mnist.test.images[i].tolist()\n",
    "    tensor_proto = tf.make_tensor_proto(values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32)\n",
    "    predict_response = mnist_predictor.predict(tensor_proto)\n",
    "    \n",
    "    print(\"========================================\")\n",
    "    label = np.argmax(mnist.test.labels[i])\n",
    "    print(\"label is {}\".format(label))\n",
    "    prediction = predict_response['outputs']['classes']['int64_val'][0]\n",
    "    print(\"prediction is {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(mnist_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

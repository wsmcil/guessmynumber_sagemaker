{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST distributed training with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-3bec7422fb64>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "('Writing', 'data/train.tfrecords')\n",
      "('Writing', 'data/validation.tfrecords')\n",
      "('Writing', 'data/test.tfrecords')\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-west-2-766924284651\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1, 28, 28, 1])\r\n",
      "\r\n",
      "    # Convolutional Layer #1\r\n",
      "    conv1 = tf.layers.conv2d(\r\n",
      "        inputs=input_layer,\r\n",
      "        filters=32,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "\r\n",
      "    # Pooling Layer #1\r\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Convolutional Layer #2 and Pooling Layer #2\r\n",
      "    conv2 = tf.layers.conv2d(\r\n",
      "        inputs=pool1,\r\n",
      "        filters=64,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Dense Layer\r\n",
      "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n",
      "    dropout = tf.layers.dropout(\r\n",
      "        inputs=dense, rate=0.4, training=(mode == Modes.TRAIN))\r\n",
      "\r\n",
      "    # Logits Layer\r\n",
      "    logits = tf.layers.dense(inputs=dropout, units=10)\r\n",
      "\r\n",
      "    # Define operations\r\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\r\n",
      "        predicted_indices = tf.argmax(input=logits, axis=1)\r\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\r\n",
      "\r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.int32)\r\n",
      "        loss = tf.losses.softmax_cross_entropy(\r\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=10), logits=logits)\r\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        predictions = {\r\n",
      "            'classes': predicted_indices,\r\n",
      "            'probabilities': probabilities\r\n",
      "        }\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 784])}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n",
      "    image.set_shape([784])\r\n",
      "    image = tf.cast(image, tf.float32) * (1. / 255)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=100):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "\r\n",
      "    image, label = read_and_decode(filename_queue)\r\n",
      "    images, labels = tf.train.batch(\r\n",
      "        [image, label], batch_size=batch_size,\r\n",
      "        capacity=1000 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:In an upcoming version of the SageMaker Python SDK, framework_version will be required to create an estimator. Please add framework_version=1.11 to your constructor to avoid an error in the future.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-tensorflow-2018-10-31-21-47-50-309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-31 21:47:51 Starting - Starting the training job...\n",
      "2018-10-31 21:47:52 Starting - Launching requested ML instances......\n",
      "2018-10-31 21:49:02 Starting - Preparing the instances for training......\n",
      "2018-10-31 21:50:19 Downloading - Downloading input data..\n",
      "\u001b[31m2018-10-31 21:50:30,174 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:30,174 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:30,179 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:31,697 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:31,698 INFO - root - starting train task\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:31,703 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,219 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,220 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,220 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f74cc17cf90>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints', '_master': u'grpc://algo-1:2222'}\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,222 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33.449132: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33.449973: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,583 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,585 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,612 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[32mDownloading s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,996 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:33,997 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.007030: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.007065: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.021460: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.021488: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.037841: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.037909: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34,380 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.387368: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:34.387402: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,606 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'worker'}}\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,607 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,609 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f48d577cf90>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[32mdevice_filters: \"/job:worker/task:0\"\u001b[0m\n",
      "\u001b[32mallow_soft_placement: true\u001b[0m\n",
      "\u001b[32mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[32m}\u001b[0m\n",
      "\u001b[32m, '_global_id_in_cluster': 1, '_is_chief': False, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints', '_master': u'grpc://algo-2:2222'}\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,610 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:34,628 INFO - tensorflow - Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:35,824 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:35,830 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:35,861 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:35.934463: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:35.934516: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:36,544 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:38.782713: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:38.782752: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:39,495 INFO - tensorflow - loss = 2.3051941, step = 0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-31 21:50:32 Training - Training image download completed. Training in progress.\u001b[32m2018-10-31 21:50:40,006 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,008 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,037 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,521 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,523 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,666 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,742 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,752 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:40,841 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[32mInstructions for updating:\u001b[0m\n",
      "\u001b[32mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[32m2018-10-31 21:50:41,410 INFO - tensorflow - loss = 1.4381021, step = 5\u001b[0m\n",
      "\u001b[31m2018-10-31 21:50:55,090 INFO - tensorflow - global_step/sec: 6.54008\u001b[0m\n",
      "\u001b[32m2018-10-31 21:51:08,294 INFO - tensorflow - loss = 0.07250598, step = 190 (26.884 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:10,129 INFO - tensorflow - global_step/sec: 6.78216\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:11,554 INFO - tensorflow - loss = 0.060713522, step = 212 (32.059 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:25,349 INFO - tensorflow - global_step/sec: 6.63614\u001b[0m\n",
      "\u001b[32m2018-10-31 21:51:35,949 INFO - tensorflow - loss = 0.03767663, step = 377 (27.655 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:39,939 INFO - tensorflow - global_step/sec: 6.92216\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:43,120 INFO - tensorflow - loss = 0.020586504, step = 427 (31.566 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:51:55,058 INFO - tensorflow - global_step/sec: 6.74659\u001b[0m\n",
      "\u001b[32m2018-10-31 21:52:03,463 INFO - tensorflow - loss = 0.037664797, step = 564 (27.514 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:10,212 INFO - tensorflow - global_step/sec: 6.73107\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:14,655 INFO - tensorflow - loss = 0.04551618, step = 639 (31.535 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:25,188 INFO - tensorflow - global_step/sec: 6.87758\u001b[0m\n",
      "\u001b[32m2018-10-31 21:52:30,735 INFO - tensorflow - loss = 0.06801801, step = 750 (27.272 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:40,094 INFO - tensorflow - global_step/sec: 6.8431\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:46,364 INFO - tensorflow - loss = 0.030243235, step = 855 (31.710 sec)\u001b[0m\n",
      "\u001b[31m2018-10-31 21:52:55,582 INFO - tensorflow - global_step/sec: 6.58551\u001b[0m\n",
      "\u001b[32m2018-10-31 21:52:58,893 INFO - tensorflow - loss = 0.0031326348, step = 939 (28.158 sec)\u001b[0m\n",
      "\u001b[32m2018-10-31 21:53:07,685 INFO - tensorflow - Loss for final step: 0.046717618.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:07,639 INFO - tensorflow - Saving checkpoints for 1001 into s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10.116264: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10.116311: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10,494 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10,606 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10,625 INFO - tensorflow - Starting evaluation at 2018-10-31-21:53:10\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10,695 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:10,762 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:11,115 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:11,124 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:11,713 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:12,165 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:12,574 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:13,059 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:13,529 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:13,994 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:14,479 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:14,958 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15,390 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15,878 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15,905 INFO - tensorflow - Finished evaluation at 2018-10-31-21:53:15\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15,905 INFO - tensorflow - Saving dict for global step 1002: accuracy = 0.9866, global_step = 1002, loss = 0.040716346\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.915734: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.915774: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.931685: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.931712: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.949008: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:15.949039: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,484 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1002: s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.565949: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.565995: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.584751: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.584826: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.600589: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.600622: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.619594: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.619675: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.635629: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.635696: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.651584: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16.651617: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,694 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,752 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:16,830 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17,170 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17,170 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17,170 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.176257: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.176292: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.190969: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.190997: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.209425: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:17.209505: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.227840: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.227915: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18,263 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-west-2-766924284651/sagemaker-tensorflow-2018-10-31-21-47-50-309/checkpoints/export/Servo/temp-1541022796/saved_model.pb\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.270218: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.270248: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.650279: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.650342: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.669302: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18.669334: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18,810 INFO - tensorflow - Loss for final step: 0.015133849.\u001b[0m\n",
      "\u001b[31m2018-10-31 21:53:18,895 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1541022796/saved_model.pb\u001b[0m\n",
      "\u001b[32m2018-10-31 21:53:27,880 INFO - tf_container - master algo-1 is down, stopping parameter server\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-31 21:53:34 Uploading - Uploading generated training model\n",
      "2018-10-31 21:53:34 Completed - Training job completed\n",
      "Billable seconds: 392\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "mnist_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **```fit```** method will create a training job in two **ml.c4.xlarge** instances. The logs above will show the instances doing training, evaluation, and incrementing the number of **training steps**. \n",
    "\n",
    "In the end of the training, the training job will generate a saved model for TF serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-tensorflow-2018-10-31-21-47-50-309\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-tensorflow-2018-10-31-21-47-50-309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------"
     ]
    }
   ],
   "source": [
    "mnist_predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                             instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "========================================\n",
      "label is 7\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'int64Val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c4cc1ed6396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int64Val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'int64Val'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "for i in range(10):\n",
    "    data = mnist.test.images[i].tolist()\n",
    "    tensor_proto = tf.make_tensor_proto(values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32)\n",
    "    predict_response = mnist_predictor.predict(tensor_proto)\n",
    "    \n",
    "    print(\"========================================\")\n",
    "    label = np.argmax(mnist.test.labels[i])\n",
    "    print(\"label is {}\".format(label))\n",
    "    prediction = predict_response['outputs']['classes']['int64Val'][0]\n",
    "    print(\"prediction is {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
